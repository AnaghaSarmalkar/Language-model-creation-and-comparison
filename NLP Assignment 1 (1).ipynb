{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Natural Language Processing: Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 1. Language Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Description\n",
    "\n",
    "To train probabilistic language models to distinguish between words in different languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import udhr \n",
    "import string\n",
    "import re\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load corpus and create sets of four languages\n",
    "* English\n",
    "* French\n",
    "* Italian\n",
    "* Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = udhr.raw('English-Latin1')\n",
    "french = udhr.raw('French_Francais-Latin1')\n",
    "italian = udhr.raw('Italian_Italiano-Latin1')\n",
    "spanish = udhr.raw('Spanish_Espanol-Latin1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Train, Test and Dev sets of the languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_train, english_dev = english[0:1000], english[1000:1100]\n",
    "french_train, french_dev = french[0:1000], french[1000:1100]\n",
    "italian_train, italian_dev = italian[0:1000], italian[1000:1100]\n",
    "spanish_train, spanish_dev = spanish[0:1000], spanish[1000:1100] \n",
    "english_test = udhr.words('English-Latin1')[0:1000]\n",
    "french_test = udhr.words('French_Francais-Latin1')[0:1000]\n",
    "italian_test = udhr.words('Italian_Italiano-Latin1')[0:1000]\n",
    "spanish_test = udhr.words('Spanish_Espanol-Latin1')[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train the language model\n",
    "* The training corpus is first preprocessed to remove case sensitivity\n",
    "* The corpus is checked for any punctuation characters\n",
    "* Number of words are calculated\n",
    "* Frequency distribution of each character in the corpus is calculated using NLTK's FreqDist module. Additionally, while calculating frequency distribution it is also checked that the character is a valid alphabet.\n",
    "* Bigram and Trigram tuples are calculated by taking into account the begining and end of the word. The beginning of any word is marked as _<w_> and the end of the word is marked as _</w_>\n",
    "* Conditional frequencies for these Bigram and Trigram pairs have been calculated using NLTK's ConditionalFreqDist module.\n",
    "* The returned values: character frequencies and frequencies of bigram and trigram models are passed to the test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_set):\n",
    "    # Preprocess the training corpus\n",
    "    corpus_train1=train_set.lower()\n",
    "    corpus_train1=''.join(c for c in corpus_train1 if c not in punctuation)\n",
    "    words=corpus_train1.split()\n",
    "    fdist_char = nltk.FreqDist(ch for ch in corpus_train1 if ch.isalpha())\n",
    "    \n",
    "    # Calculate Bigram pairs\n",
    "    bigram_pairs=[]\n",
    "    for w in words:\n",
    "        for i in range (len(w)):\n",
    "            if i ==0:\n",
    "                bigram_pairs.append((\"<w>\",w[i]))\n",
    "            if i<len(w)-1:\n",
    "                bigram_pairs.append((w[i],w[i+1]))\n",
    "            if i == len(w)-1:\n",
    "                bigram_pairs.append((w[i],\"</w>\"))\n",
    "                \n",
    "    # Calculate cdf for bigram pairs\n",
    "    cfd = nltk.ConditionalFreqDist(bigram_pairs)\n",
    "    \n",
    "    # Calculate Trigram pairs\n",
    "    trigram_pairs=[]\n",
    "    for w in words:\n",
    "        for i in range (len(w)-1):\n",
    "            if i ==0:\n",
    "                trigram_pairs.append((\"<w>\",w[i]))\n",
    "                trigram_pairs.append((\"<w>\"+w[i],w[i+1]))\n",
    "        if i<len(w)-2:\n",
    "                trigram_pairs.append((w[i:i+2],w[i+2]))\n",
    "        if i==len(w)-2:\n",
    "                trigram_pairs.append((w[i:i+2],\"</w>\"))\n",
    "                trigram_pairs.append((w[i+1],\"</w>\"))\n",
    "    \n",
    "    # Calculate cdf for trigram pairs\n",
    "    cfd1 = nltk.ConditionalFreqDist(trigram_pairs)\n",
    "    \n",
    "    return fdist_char, cfd, cfd1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Test the language model and calculate probabilities\n",
    "\n",
    "* The test_data is processed to make the words case insensitive\n",
    "* While calculating Unigram, Bigram and Trigram probabilities, Laplace Smoothing (Add One) has been used. \n",
    "* Laplace Smoothing adds 1 to every count. The denominator is accordingly adjusted by adding V which is the total character vocabulary that we have. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_data,fdist_char,cfd,cfd1):\n",
    "    #Preprocessing: making words case insensitive\n",
    "    corpus_test= [w.lower() for w in test_data]\n",
    "    uni={}\n",
    "    \n",
    "    # Calculate Unigram probailities\n",
    "    for w in corpus_test:\n",
    "        prob_u=1\n",
    "        for i in range(len(w)):\n",
    "            prob_u*=(1+fdist_char[w[i]])/(len(fdist_char.keys())+sum(fdist_char.values()))\n",
    "        uni[w]=prob_u\n",
    "        \n",
    "    # Calculate Bigram probailities\n",
    "    bi={}\n",
    "    for w in corpus_test:\n",
    "        prob=1\n",
    "        prob1=1\n",
    "        prob2=1\n",
    "        for i in range(len(w)):\n",
    "            if i==0:\n",
    "                prob1=(1+cfd['<w>'][w[i]])/(len(fdist_char.keys()) +sum(cfd['<w>'].values()))\n",
    "            if i<len(w)-1:\n",
    "                prob=prob*(cfd[w[i]][w[i+1]])/(len(fdist_char.keys())+ sum(cfd[w[i]].values()))\n",
    "            if i== len(w)-1:\n",
    "                prob2=(1+cfd[w[i]]['</w>'])/(len(fdist_char.keys())+sum(cfd[w[i]].values()))\n",
    "        bi[w]=prob*prob1*prob2\n",
    "        \n",
    "    # Calculate Trigram probabilities\n",
    "    tri={}\n",
    "    for w in corpus_test:\n",
    "        prob=1\n",
    "        prob1=1\n",
    "        prob2=1\n",
    "        prob3=1\n",
    "        for i in range(len(w)):\n",
    "            if i==0:\n",
    "                prob1=(1+cfd1['<w>'][w[i]])/(len(fdist_char.keys()) +sum(cfd1['<w>'].values()))\n",
    "            if i==1:\n",
    "                prob3=(1+cfd1['<w>'+w[i-1]][w[i]])/(len(fdist_char.keys()) +sum(cfd1['<w>'+w[i-1]].values()))\n",
    "            if i<len(w)-1:\n",
    "                prob=prob*(1+cfd1[w[i-1]+w[i]][w[i+1]])/(len(fdist_char.keys())+ sum(cfd1[w[i-1]+w[i]].values()))\n",
    "            if i==len(w)-1:\n",
    "                prob2=(1+cfd1[w[i-1]+w[i]]['</w>'])/(len(fdist_char.keys())+sum(cfd1[w[i-1]+w[i]].values()))\n",
    "                prob2=prob2*(1+cfd1[w[i]]['</w>'])/(len(fdist_char.keys()) +sum(cfd1[w[i]].values()))\n",
    "        tri[w]=prob*prob1*prob2*prob3\n",
    "        \n",
    "    return uni, bi, tri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Train models for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_char_eng,cfd_eng,cfd1_eng=train_model(english_train)\n",
    "fdist_char_fre,cfd_fre,cfd1_fre=train_model(french_train)\n",
    "fdist_char_spa,cfd_spa,cfd1_spa=train_model(spanish_train)\n",
    "fdist_char_ita,cfd_ita,cfd1_ita=train_model(italian_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Comparison of English and French Unigram, Bigram and Trigram Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Using English Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_eng, bi_eng, tri_eng=test_model(english_test,fdist_char_eng,cfd_eng,cfd1_eng)\n",
    "uni_fre, bi_fre, tri_fre=test_model(english_test,fdist_char_fre,cfd_fre,cfd1_fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Unigram models is:  68.1 %\n",
      "Accuracy for Bigram model is:  75.9 %\n",
      "Accuracy for Trigram model is:  90.8 %\n"
     ]
    }
   ],
   "source": [
    "english_test1=[w.lower() for w in english_test]\n",
    "correct_count_uni=0\n",
    "correct_count_bi=0\n",
    "correct_count_tri=0\n",
    "\n",
    "for i in english_test1:\n",
    "    if uni_fre[i]<uni_eng[i]:\n",
    "        correct_count_uni+=1\n",
    "    if bi_fre[i]<bi_eng[i]:\n",
    "        correct_count_bi+=1\n",
    "    if tri_fre[i]<tri_eng[i]:\n",
    "        correct_count_tri+=1\n",
    "print(\"Accuracy on Unigram models is: \", round(correct_count_uni/len(english_test)*100,2), \"%\")\n",
    "print(\"Accuracy for Bigram model is: \", round(correct_count_bi/len(english_test)*100,2),\"%\")\n",
    "print(\"Accuracy for Trigram model is: \", round(correct_count_tri/len(english_test)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Using French Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_eng, bi_eng, tri_eng=test_model(french_test,fdist_char_eng,cfd_eng,cfd1_eng)\n",
    "uni_fre, bi_fre, tri_fre=test_model(french_test,fdist_char_fre,cfd_fre,cfd1_fre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Unigram models is:  85.4 %\n",
      "Accuracy for Bigram model is:  58.3 %\n",
      "Accuracy for Trigram model is:  64.5 %\n"
     ]
    }
   ],
   "source": [
    "french_test1=[w.lower() for w in french_test]\n",
    "correct_count_uni=0\n",
    "correct_count_bi=0\n",
    "correct_count_tri=0\n",
    "\n",
    "for i in french_test1:\n",
    "    if uni_fre[i]>uni_eng[i]:\n",
    "        correct_count_uni+=1\n",
    "    if bi_fre[i]>bi_eng[i]:\n",
    "        correct_count_bi+=1\n",
    "    if tri_fre[i]>tri_eng[i]:\n",
    "        correct_count_tri+=1\n",
    "print(\"Accuracy on Unigram models is: \", round(correct_count_uni/len(french_test)*100,2), \"%\")\n",
    "print(\"Accuracy for Bigram model is: \", round(correct_count_bi/len(french_test)*100,2),\"%\")\n",
    "print(\"Accuracy for Trigram model is: \", round(correct_count_tri/len(french_test)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Anaysis\n",
    "\n",
    "* Ideally the accuracies should be Trigram>Bigram>Unigram where accuracy of Trigram is the highest and that of Unigram is the lowest.\n",
    "* Here we can see this case when english_test was trained on English and French model. The better accuracies are due to the English test set which aided the English model in assigning higher probability to the words.\n",
    "* On the other hand, the models did not fare well according to ideal order of accuracies for the french_set. This could be due to the sparsity of the CDF matrix or the choice of Smoothing function used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 2. Language Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Comparison of Spanish and Italian Unigram, Bigram and Trigram Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Using Spanish Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_spa, bi_spa, tri_spa=test_model(spanish_test,fdist_char_spa,cfd_spa,cfd1_spa)\n",
    "uni_ita, bi_ita, tri_ita=test_model(spanish_test,fdist_char_ita,cfd_ita,cfd1_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Unigram models is:  73.7 %\n",
      "Accuracy for Bigram model is:  60.2 %\n",
      "Accuracy for Trigram model is:  57.2 %\n"
     ]
    }
   ],
   "source": [
    "spanish_test1=[w.lower() for w in spanish_test]\n",
    "correct_count_uni=0\n",
    "correct_count_bi=0\n",
    "correct_count_tri=0\n",
    "\n",
    "for i in spanish_test1:\n",
    "    if uni_spa[i]>uni_ita[i]:\n",
    "        correct_count_uni+=1\n",
    "    if bi_spa[i]>bi_ita[i]:\n",
    "        correct_count_bi+=1\n",
    "    if tri_spa[i]>tri_ita[i]:\n",
    "        correct_count_tri+=1\n",
    "print(\"Accuracy on Unigram models is: \", round(correct_count_uni/len(spanish_test)*100,2), \"%\")\n",
    "print(\"Accuracy for Bigram model is: \", round(correct_count_bi/len(spanish_test)*100,2),\"%\")\n",
    "print(\"Accuracy for Trigram model is: \", round(correct_count_tri/len(spanish_test)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Using Italian Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_spa, bi_spa, tri_spa=test_model(italian_test,fdist_char_spa,cfd_spa,cfd1_spa)\n",
    "uni_ita, bi_ita, tri_ita=test_model(italian_test,fdist_char_ita,cfd_ita,cfd1_ita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Unigram models is:  56.0 %\n",
      "Accuracy for Bigram model is:  68.9 %\n",
      "Accuracy for Trigram model is:  84.6 %\n"
     ]
    }
   ],
   "source": [
    "italian_test1=[w.lower() for w in italian_test]\n",
    "correct_count_uni=0\n",
    "correct_count_bi=0\n",
    "correct_count_tri=0\n",
    "\n",
    "for i in italian_test1:\n",
    "    if uni_spa[i]<uni_ita[i]:\n",
    "        correct_count_uni+=1\n",
    "    if bi_spa[i]<bi_ita[i]:\n",
    "        correct_count_bi+=1\n",
    "    if tri_spa[i]<tri_ita[i]:\n",
    "        correct_count_tri+=1\n",
    "print(\"Accuracy on Unigram models is: \", round(correct_count_uni/len(italian_test)*100,2), \"%\")\n",
    "print(\"Accuracy for Bigram model is: \", round(correct_count_bi/len(italian_test)*100,2),\"%\")\n",
    "print(\"Accuracy for Trigram model is: \", round(correct_count_tri/len(italian_test)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analysis\n",
    "\n",
    "Judging by the frequencies, the Spanish, Italian language pairs were harder to distinguish. This could be due to limited training data set which was not diverse."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
